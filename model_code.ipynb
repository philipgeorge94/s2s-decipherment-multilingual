{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "685 Project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Ug_U0PQ6kIe",
        "outputId": "957f2430-dcdf-424d-ab0f-6d1be2e71806"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.13.0-py3-none-any.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 9.2 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 32.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 37.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.2.1-py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 455 kB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 39.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.2.1 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.13.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install solver"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQETpg59X7vL",
        "outputId": "a53e4cee-e4c6-4e9a-9312-c207c9a5b54e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting solver\n",
            "  Downloading solver-0.0.4.tar.gz (2.8 kB)\n",
            "Building wheels for collected packages: solver\n",
            "  Building wheel for solver (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for solver: filename=solver-0.0.4-py3-none-any.whl size=3128 sha256=9a6be2829694000521590f8a7df0543614022e287fcde124f8744a2e76f3b209\n",
            "  Stored in directory: /root/.cache/pip/wheels/66/27/02/f951263ae7f5f0d6b627987a9ca9baefdb4da1f5c6f18fb4f5\n",
            "Successfully built solver\n",
            "Installing collected packages: solver\n",
            "Successfully installed solver-0.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from preprocess import *\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(device)"
      ],
      "metadata": {
        "id": "IR7WNONnn_aL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea073998-0054-45da-893b-4ed8b1cbc5e3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Preprocess**"
      ],
      "metadata": {
        "id": "_H_mgvqJHbB4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "space_code = '26'\n",
        "pad_code = '27'\n",
        "max_len = 256\n",
        "\n",
        "def read_file(filename = \"\"):\n",
        "      lines = []\n",
        "      with open(filename, 'r') as file:\n",
        "          for line in file.readlines():\n",
        "              if line != \"\\n\":\n",
        "                  lines.append((line.strip()).replace(' ',''))\n",
        "      return lines\n",
        "\n",
        "def freq_array(line):\n",
        "    freq_str = frequency_encode_string(line)\n",
        "    freq_str = freq_str.replace('_',space_code)\n",
        "    freq_arr = [int(x) for x in freq_str.split()]\n",
        "    return freq_arr + [int(pad_code)] * (max_len - len(freq_arr))\n",
        "\n",
        "def get_tensor_file(filename=\"\"):\n",
        "      strp_lines = read_file(filename)\n",
        "      freq_lines = []\n",
        "      for line in strp_lines:\n",
        "          freq_lines.append(freq_array(line))\n",
        "      return torch.tensor(freq_lines), strp_lines"
      ],
      "metadata": {
        "id": "wanvt0whYtyj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lines,tgt = get_tensor_file('/content/drive/MyDrive/cs685/project/gutenberg-data/catalan.train')\n",
        "lines.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6csTv4m6Q7r",
        "outputId": "4bb7f8b2-71f0-496b-d0b0-47b2f93d3807"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([71780, 256])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_token = '28'\n",
        "end_token = '29'\n",
        "alphabets = 'abcdefghijklmnopqrstuvwxyz'\n",
        "vocab_size = 30\n",
        "alphabet_dict = {}\n",
        "alphabet_dict['start'] = int(start_token) \n",
        "alphabet_dict['end'] = int(end_token)\n",
        "alphabet_dict['_'] = int(space_code)\n",
        "alphabet_dict['pad'] = int(pad_code)\n",
        "alphabet_idx = 0\n",
        "\n",
        "for character in alphabets:\n",
        "    alphabet_dict[character] = alphabet_idx\n",
        "    alphabet_idx += 1\n",
        "\n",
        "\n",
        "def one_hot_encode(sent,start = True, end = True):\n",
        "    num_code = []\n",
        "    input_code = []\n",
        "    if start:\n",
        "        one_code = [0] * vocab_size\n",
        "        one_code[alphabet_dict['start']] = 1\n",
        "        num_code.append(one_code)\n",
        "\n",
        "        input_code.append(alphabet_dict['start'])\n",
        "\n",
        "    for character in sent:\n",
        "        one_code = [0] * vocab_size\n",
        "        one_code[alphabet_dict[character]] = 1\n",
        "        num_code.append(one_code)\n",
        "\n",
        "        input_code.append(alphabet_dict[character])\n",
        "\n",
        "    if end:\n",
        "        one_code = [0] * vocab_size\n",
        "        one_code[alphabet_dict['end']] = 1\n",
        "        num_code.append(one_code)\n",
        "\n",
        "        input_code.append(alphabet_dict['end'])\n",
        "\n",
        "    for i in range(len(num_code), max_len):\n",
        "        one_code = [0] * vocab_size\n",
        "        one_code[alphabet_dict['pad']] = 1\n",
        "        num_code.append(one_code)\n",
        "\n",
        "        input_code.append(alphabet_dict['pad'])\n",
        "\n",
        "    return num_code, input_code\n",
        "\n",
        "def one_hot_code_vocab(lines, start = True, end = True):\n",
        "    one_hot_codes = []\n",
        "    input_codes = []\n",
        "    for line in lines:\n",
        "        num_code, input_code = one_hot_encode(line, start, end)\n",
        "        one_hot_codes.append(num_code) \n",
        "        input_codes.append(input_code)\n",
        "    return torch.FloatTensor(one_hot_codes), torch.tensor(input_codes)\n"
      ],
      "metadata": {
        "id": "0DSJaJTZfdlV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_batch(torch_lines, target, batch_idx, batch_size = 32):\n",
        "      start_idx = (batch_idx * batch_size)\n",
        "      end_idx = min((batch_idx + 1)*batch_size, len(target))\n",
        "\n",
        "      one_hot_codes, input_codes = one_hot_code_vocab(target[start_idx : end_idx])\n",
        "      return torch_lines[start_idx : end_idx], input_codes, one_hot_codes, target[start_idx : end_idx]"
      ],
      "metadata": {
        "id": "ddoPbHCYnJv-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model**"
      ],
      "metadata": {
        "id": "WmAfQs0t_0_b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "class PositionalEncoding(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        position = torch.arange(max_len).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
        "        pe = torch.zeros(max_len, 1, d_model)\n",
        "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: Tensor, shape [seq_len, batch_size, embedding_dim]\n",
        "        \"\"\"\n",
        "        x = x + self.pe[:x.size(0)]\n",
        "        return self.dropout(x)"
      ],
      "metadata": {
        "id": "gAkb1LGLA-g9"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification, AdamW, DataCollatorWithPadding, \\\n",
        "    get_scheduler\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm.auto import tqdm\n",
        "# from utils import *\n",
        "from solver import *\n",
        "from torch.nn import Transformer, TransformerEncoder, TransformerEncoderLayer, TransformerDecoderLayer, TransformerDecoder\n",
        "import math\n",
        "\n",
        "dropout_prob = 0\n",
        "vocab_size = 30\n",
        "\n",
        "class Deciphormer(torch.nn.Module):\n",
        "    '''\n",
        "    Defining the base model:\n",
        "    1)\n",
        "    '''\n",
        "\n",
        "    def __init__(self, ntoken: int = 30, d_model: int = 512, nhead: int = 8, d_hid: int = 2048, nlayers: int = 6,\n",
        "                 dropout: float = 0.5):\n",
        "        # Initialize model attributes\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.nhead = nhead\n",
        "        self.d_hid = d_hid\n",
        "        self.nlayers = nlayers\n",
        "        self.dropout = dropout\n",
        "\n",
        "        # Define model layers\n",
        "\n",
        "        self.embedder = nn.Embedding(ntoken, d_model)\n",
        "        self.pos_encoder = PositionalEncoding(d_model, max_len = d_model)\n",
        "        encoder_layers = TransformerEncoderLayer(self.d_model, nhead, d_hid, dropout, batch_first = True)\n",
        "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
        "\n",
        "        self.embedder2 = nn.Embedding(vocab_size, d_model)\n",
        "        decoder_layers = TransformerDecoderLayer(d_model, nhead, d_hid, batch_first = True)\n",
        "        self.transformer_decoder = TransformerDecoder(decoder_layers, nlayers)\n",
        "        self.linearout = nn.Linear(d_model, vocab_size)\n",
        "\n",
        "    def forward(self, data, tgt, mask=None):\n",
        "      src = self.embedder(data) * math.sqrt(self.d_model)\n",
        "      # print(src.shape)\n",
        "      src = self.pos_encoder(src)\n",
        "      # print(src.shape)\n",
        "      out1 = self.transformer_encoder(src, mask)\n",
        "      # print(out1.shape)\n",
        "\n",
        "      embed_tgt = self.embedder2(tgt) * math.sqrt(self.d_model)\n",
        "      out2 = self.transformer_decoder(embed_tgt, out1)\n",
        "      out2 = self.linearout(out2)\n",
        "      return (out1, out2)\n"
      ],
      "metadata": {
        "id": "ytC-UJV4--sG"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Deciphormer()\n",
        "model.cuda()\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjO0xBGRBVH5",
        "outputId": "f4295706-15a5-4bb2-925a-b5b15a5f0a9a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Deciphormer(\n",
              "  (embedder): Embedding(30, 512)\n",
              "  (pos_encoder): PositionalEncoding(\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (transformer_encoder): TransformerEncoder(\n",
              "    (layers): ModuleList(\n",
              "      (0): TransformerEncoderLayer(\n",
              "        (self_attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "        (dropout): Dropout(p=0.5, inplace=False)\n",
              "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout1): Dropout(p=0.5, inplace=False)\n",
              "        (dropout2): Dropout(p=0.5, inplace=False)\n",
              "      )\n",
              "      (1): TransformerEncoderLayer(\n",
              "        (self_attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "        (dropout): Dropout(p=0.5, inplace=False)\n",
              "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout1): Dropout(p=0.5, inplace=False)\n",
              "        (dropout2): Dropout(p=0.5, inplace=False)\n",
              "      )\n",
              "      (2): TransformerEncoderLayer(\n",
              "        (self_attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "        (dropout): Dropout(p=0.5, inplace=False)\n",
              "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout1): Dropout(p=0.5, inplace=False)\n",
              "        (dropout2): Dropout(p=0.5, inplace=False)\n",
              "      )\n",
              "      (3): TransformerEncoderLayer(\n",
              "        (self_attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "        (dropout): Dropout(p=0.5, inplace=False)\n",
              "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout1): Dropout(p=0.5, inplace=False)\n",
              "        (dropout2): Dropout(p=0.5, inplace=False)\n",
              "      )\n",
              "      (4): TransformerEncoderLayer(\n",
              "        (self_attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "        (dropout): Dropout(p=0.5, inplace=False)\n",
              "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout1): Dropout(p=0.5, inplace=False)\n",
              "        (dropout2): Dropout(p=0.5, inplace=False)\n",
              "      )\n",
              "      (5): TransformerEncoderLayer(\n",
              "        (self_attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "        (dropout): Dropout(p=0.5, inplace=False)\n",
              "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout1): Dropout(p=0.5, inplace=False)\n",
              "        (dropout2): Dropout(p=0.5, inplace=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (embedder2): Embedding(30, 512)\n",
              "  (transformer_decoder): TransformerDecoder(\n",
              "    (layers): ModuleList(\n",
              "      (0): TransformerDecoderLayer(\n",
              "        (self_attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (multihead_attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout1): Dropout(p=0.1, inplace=False)\n",
              "        (dropout2): Dropout(p=0.1, inplace=False)\n",
              "        (dropout3): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (1): TransformerDecoderLayer(\n",
              "        (self_attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (multihead_attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout1): Dropout(p=0.1, inplace=False)\n",
              "        (dropout2): Dropout(p=0.1, inplace=False)\n",
              "        (dropout3): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (2): TransformerDecoderLayer(\n",
              "        (self_attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (multihead_attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout1): Dropout(p=0.1, inplace=False)\n",
              "        (dropout2): Dropout(p=0.1, inplace=False)\n",
              "        (dropout3): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (3): TransformerDecoderLayer(\n",
              "        (self_attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (multihead_attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout1): Dropout(p=0.1, inplace=False)\n",
              "        (dropout2): Dropout(p=0.1, inplace=False)\n",
              "        (dropout3): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (4): TransformerDecoderLayer(\n",
              "        (self_attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (multihead_attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout1): Dropout(p=0.1, inplace=False)\n",
              "        (dropout2): Dropout(p=0.1, inplace=False)\n",
              "        (dropout3): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (5): TransformerDecoderLayer(\n",
              "        (self_attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (multihead_attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout1): Dropout(p=0.1, inplace=False)\n",
              "        (dropout2): Dropout(p=0.1, inplace=False)\n",
              "        (dropout3): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (linearout): Linear(in_features=512, out_features=30, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.train()\n",
        "batch_size = 32\n",
        "num_of_batches = lines.shape[0]//batch_size\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(),lr = 0.01)\n",
        "loss = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "for i in range(num_of_batches):\n",
        "    encoder_input, decoder_tgt, decoder_final,_ = get_batch(lines, tgt, i)\n",
        "\n",
        "    encoder_input = encoder_input.to(device)\n",
        "    decoder_tgt = decoder_tgt.to(device)\n",
        "    decoder_final = decoder_final.to(device)\n",
        "\n",
        "    model_encoder_out, model_decoder_out = model(encoder_input, decoder_tgt)\n",
        "\n",
        "    loss_tensor = loss(model_decoder_out,decoder_final)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss_tensor.backward()\n",
        "    optimizer.step()\n",
        "    print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vyrXe002oCUa",
        "outputId": "61208706-d272-487d-bead-e43aa891e1f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(lines.shape[0]/32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKHVjZqv1exF",
        "outputId": "047bfda8-9f08-4a32-f286-3be77a6e6277"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2243.125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Evaluation**"
      ],
      "metadata": {
        "id": "ggRzd2F48e9m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval_src, eval_tgt = get_tensor_file('/content/drive/MyDrive/cs685/project/gutenberg-data/catalan.test')"
      ],
      "metadata": {
        "id": "InaXcT7R8efr"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rev_alphabet = {}\n",
        "for key in alphabet_dict.keys():\n",
        "    rev_alphabet[alphabet_dict[key]] = key"
      ],
      "metadata": {
        "id": "Ne_397I5A_TG"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "num_of_batches = eval_src.shape[0]\n",
        "\n",
        "for i in range(num_of_batches):\n",
        "    encoder_input, decoder_tgt, decoder_final, target_sentences = get_batch(eval_src, eval_tgt, i, batch_size = 1)\n",
        "    encoder_input = encoder_input.to(device)\n",
        "    pred_sentence = ''\n",
        "    for j in range(max_len):\n",
        "        decoder_one_hot, decoder_tgt = one_hot_code_vocab([pred_sentence], start = True, end = False)\n",
        "        decoder_tgt = decoder_tgt.to(device)\n",
        "\n",
        "        model_encoder_out, model_decoder_out = model(encoder_input, decoder_tgt)\n",
        "        logits = model_decoder_out.detach().cpu().numpy()\n",
        "        \n",
        "        logits = logits.squeeze()\n",
        "\n",
        "        pred_char = np.argmax(logits[j])\n",
        "        if(pred_char == end_token):\n",
        "              break\n",
        "        elif(pred_char == space_token):\n",
        "              pred_sentence = ' '\n",
        "        elif(pred_char < 26):\n",
        "              pred_sentence += rev_alphabet[pred_char]\n",
        "    print(pred_sentence)\n",
        "    print(target_sentences)\n",
        "    print('-'*20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNdatG0_8zZi",
        "outputId": "b7b4f7f4-fc6b-4610-dc29-5ef7d7e70592"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "startstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstart\n",
            "['larribada_del_cinque_cosa_dolca_seria_pera_mi_la_seva_vinguda']\n",
            "--------------------\n",
            "startstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstart\n",
            "['sir_tobias_per_deu']\n",
            "--------------------\n",
            "startstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstart\n",
            "['si_certament_nhi_tinc_una_pero_que']\n",
            "--------------------\n",
            "startstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstart\n",
            "['jo_y_que_tingui_damunt_della_linfluencia']\n",
            "--------------------\n",
            "startstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstart\n",
            "['llureia_que_fem_jessica_que_no_vens']\n",
            "--------------------\n",
            "startstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstart\n",
            "['filtra_a_lorella_del_nuvi_ensomniat_y_el_crida_a_casament']\n",
            "--------------------\n",
            "startstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstart\n",
            "['exteriors_ab_una_expressio_daviditat_tant']\n",
            "--------------------\n",
            "startstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstart\n",
            "['de_pau_y_coram']\n",
            "--------------------\n",
            "startstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstart\n",
            "['percaca_preparemnos_al_combat_foc']\n",
            "--------------------\n",
            "startstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstart\n",
            "['acabeu_dun_cop_mestressa']\n",
            "--------------------\n",
            "startstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstart\n",
            "['esposa_al_saber_quant_jo_me_la_mereixo_aquesta_anell_hauria']\n",
            "--------------------\n",
            "startstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstart\n",
            "['me_roba_la_facultad_descullir_lliurement_pero_si_el_meu_pare']\n",
            "--------------------\n",
            "startstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstart\n",
            "['entra_evans']\n",
            "--------------------\n",
            "startstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstart\n",
            "['com_hi_hauria_guanyat_la_meva_cabellera']\n",
            "--------------------\n",
            "startstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstart\n",
            "['masia_aon_la_senyoreta_anna_esta_invitada']\n",
            "--------------------\n",
            "startstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstart\n",
            "['bon_gobbo_o_be_bon_lancelot_gobbo_estira_les_cames_pren']\n",
            "--------------------\n",
            "startstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstart\n",
            "['mateixa_com_a_una_inconeguda_per_forca_ha']\n",
            "--------------------\n",
            "startstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstart\n",
            "['el_meu_amo_senyor_el_meu_amo_el_senyor']\n",
            "--------------------\n",
            "startstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstart\n",
            "['ple_de_pardalets_que_han_de_fer_els']\n",
            "--------------------\n",
            "startstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstart\n",
            "['si_no_sesporugueix_almenys_sera_avergonyit']\n",
            "--------------------\n",
            "startstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstart\n",
            "['a_que_ve_lhistoria']\n",
            "--------------------\n",
            "startstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstart\n",
            "['meves_intencions_sigui_pels_meus_esforcos']\n",
            "--------------------\n",
            "startstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstart\n",
            "['reposava_cressida']\n",
            "--------------------\n",
            "startstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstart\n",
            "['la_tornada_cap_llit_tindra_la_culpa_del_meu_retard_cap_repos']\n",
            "--------------------\n",
            "startstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstart\n",
            "['veusaqui_anna_la_gentil_damisela']\n",
            "--------------------\n",
            "startstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstart\n",
            "['casa_vull_dirte_les_finestres_que_ni_el_soroll_deixa_buida']\n",
            "--------------------\n",
            "startstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstart\n",
            "['tres_hores_y_no_es_vingut']\n",
            "--------------------\n",
            "startstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstart\n",
            "['es_molt_veritat_oh_sabi_jutge_equitatiu_quan_mes_vell_ets_de']\n",
            "--------------------\n",
            "startstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstart\n",
            "['he_sigut_culpable_senyor_page_y_pago_la']\n",
            "--------------------\n",
            "startstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstart\n",
            "['al_contrari_sense_cap_llastima']\n",
            "--------------------\n",
            "startstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstart\n",
            "['aixeribiuse_o_resigneuvos_al_paper_de_sir']\n",
            "--------------------\n",
            "startstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstart\n",
            "['mala_negada_no_es_aquesta_la_moda_de']\n",
            "--------------------\n",
            "startstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstart\n",
            "['compassio_mireusel_limbecil_que_deixava_diners_sense_interes']\n",
            "--------------------\n",
            "startstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstart\n",
            "['sigueu_franc']\n",
            "--------------------\n",
            "startstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstart\n",
            "['peus_a_casa_ja_ho_estic_veient_deu_esser']\n",
            "--------------------\n",
            "startstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstart\n",
            "['conteu_que_autorisades_com_estem_per_la']\n",
            "--------------------\n",
            "startstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstart\n",
            "['sense_llibres']\n",
            "--------------------\n",
            "startstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstart\n",
            "['lorella_aixo_es_estil_enfatic']\n",
            "--------------------\n",
            "startstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstart\n",
            "['ques_reti_si_algu_pot_vencela_sou_vos_mes']\n",
            "--------------------\n",
            "startstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstart\n",
            "['renou_adins']\n",
            "--------------------\n",
            "startstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstart\n",
            "['millor_y_si_no_que_hi_farem_aixi_com_lunic_banyut']\n",
            "--------------------\n",
            "startstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstart\n",
            "['anna_sotmesa_en_apariencia_als_progectes']\n",
            "--------------------\n",
            "startstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstart\n",
            "['ganes_dexperimentarlo']\n",
            "--------------------\n",
            "startstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstart\n",
            "['ets_el_deu_mart_dels_descontents_jo']\n",
            "--------------------\n",
            "startstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstart\n",
            "['passada_de_la_que_sen_recordi_tota_la_vida_y_nol_faig_esser']\n",
            "--------------------\n",
            "startstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstart\n",
            "['es_shylock_vostre_nom']\n",
            "--------------------\n",
            "startstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstart\n",
            "['taparem_ab_roba_bruta_com_si_lenviessiu']\n",
            "--------------------\n",
            "startstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstart\n",
            "['pretenciosament_discret_que_no_fassi_altra_cosa_que_censurar']\n",
            "--------------------\n",
            "startstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstart\n",
            "['com_si_elles_no_haguessin_sofert_de_bo']\n",
            "--------------------\n",
            "startstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstart\n",
            "['el_meu_poder_me_permet_disoldrel_tribunal_a_no_esser_que']\n",
            "--------------------\n",
            "startstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstart\n",
            "['deixemlo_no_el_seguire_mes_ab_pregs_inutils_atenta_contra_ma']\n",
            "--------------------\n",
            "startstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstart\n",
            "['vos_me_sigui_assegurada_firmada_y_confirmada']\n",
            "--------------------\n",
            "startstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstart\n",
            "['entren_la_senyora_page_la_senyora']\n",
            "--------------------\n",
            "startstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstart\n",
            "['matat_aquesta_pobre_dona']\n",
            "--------------------\n",
            "startstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstart\n",
            "['que_vaig_riure_de_debo_te_vaig_enviar_un_vintidos_perque']\n",
            "--------------------\n",
            "startstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstart\n",
            "['fortuna_podria_fallar_en_allo_que_obtindra_un_de_menys_digne_y']\n",
            "--------------------\n",
            "startstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstart\n",
            "['mala_negada_jo_dic_igual_no_hi_ni_una_rata']\n",
            "--------------------\n",
            "startstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstart\n",
            "['dona_encara_li_havia_de_preguntar_altres']\n",
            "--------------------\n",
            "startstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstart\n",
            "['el_frondos_ornament_sigui_llegat_a_vostres']\n",
            "--------------------\n",
            "startstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstart\n",
            "['aquest_cas_foren_els_pecats_de_la_meva_mare_els_que_caurien']\n",
            "--------------------\n",
            "startstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstart\n",
            "['poc_avenca_qui_sespera']\n",
            "--------------------\n",
            "startstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstart\n",
            "['donar_me_jurareu_que_la_portarieu_fins_a_lhora_de_la_mort_y_que']\n",
            "--------------------\n",
            "startstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstart\n",
            "['aquestes_coses_que_entre_nosaltres_te_fan_encara_gracia_y_que_cap']\n",
            "--------------------\n",
            "startstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstart\n",
            "['justicia_tindras_pots_estarne_segur_y_mes_de_la_que_desitges']\n",
            "--------------------\n",
            "startstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstart\n",
            "['pel_treball_menjarem_un_bon_petit_apat']\n",
            "--------------------\n",
            "startstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstart\n",
            "['aquesta_lletra_llegiula_quan_us_vagui_ve_de_padua_de_bellario']\n",
            "--------------------\n",
            "startstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstart\n",
            "['benvolguts_impediuli_que_bati_aquesta']\n",
            "--------------------\n",
            "startstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstart\n",
            "['aquest_putiner_belitre_de_les_riotes_y']\n",
            "--------------------\n",
            "startstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstart\n",
            "['desseguida_jo_els_he_fet_aquests_estropicis']\n",
            "--------------------\n",
            "startstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstart\n",
            "['sesborren_mes_aviat_que_les_de_les_dones']\n",
            "--------------------\n",
            "startstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstart\n",
            "['pot_fer_caure_el_mellor_punt_de_la_ma_del_mes_feble_y_alcides']\n",
            "--------------------\n",
            "startstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstartstart\n",
            "['si_haguessiu_conegut_la_virtut_de_lanell_o_pressentit_la_valua']\n",
            "--------------------\n"
          ]
        }
      ]
    }
  ]
}