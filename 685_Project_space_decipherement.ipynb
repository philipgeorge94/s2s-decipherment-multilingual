{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Ug_U0PQ6kIe"
      },
      "outputs": [],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZQETpg59X7vL"
      },
      "outputs": [],
      "source": [
        "!pip install solver"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IR7WNONnn_aL"
      },
      "outputs": [],
      "source": [
        "from preprocess import *\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_H_mgvqJHbB4"
      },
      "source": [
        "# **Preprocess**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wanvt0whYtyj"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "space_code = ''\n",
        "pad_code = '27'\n",
        "max_len = 256\n",
        "\n",
        "def read_file(filename = \"\"):\n",
        "      lines = []\n",
        "      with open(filename, 'r') as file:\n",
        "          for line in file.readlines():\n",
        "              if line != \"\\n\":\n",
        "                  lines.append((line.strip()).replace(' ',''))\n",
        "      return lines\n",
        "\n",
        "def freq_array(line):\n",
        "    freq_str = frequency_encode_string(line)\n",
        "    freq_str = freq_str.replace('_',space_code)\n",
        "    freq_arr = [int(x) for x in freq_str.split()]\n",
        "    return freq_arr + [int(pad_code)] * (max_len - len(freq_arr))\n",
        "\n",
        "def get_tensor_file(file_dir=\"\", file_type=\".test\"):\n",
        "      # file_list = glob.glob(file_dir + \"*\" + file_type)\n",
        "      file_list = [file_dir]\n",
        "      freq_lines = []\n",
        "      source_lines = []\n",
        "      for filename in file_list:\n",
        "          strp_lines = read_file(filename)\n",
        "          for line in strp_lines:\n",
        "              freq_lines.append(freq_array(line))\n",
        "          freq_lines.append([x.replace('_','') for x in strp_lines])\n",
        "          source_lines.extend(strp_lines)\n",
        "      return freq_lines, source_lines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i6csTv4m6Q7r"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "lines_arr = []\n",
        "tgt_arr = []\n",
        "lang_arr = []\n",
        "i = 0\n",
        "files = glob.glob('/content/drive/MyDrive/' + \"*\" + '.train')\n",
        "print(files)\n",
        "for i,filename in enumerate(files):\n",
        "    print(filename)\n",
        "    lines,tgt = get_tensor_file(filename)\n",
        "    lines_arr.append(lines)\n",
        "    tgt_arr.append(tgt)\n",
        "    lang_arr.append(i)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tr88FWAeaz4P"
      },
      "outputs": [],
      "source": [
        "take = 100000\n",
        "red_tuple = []\n",
        "for i in range(len(lines_arr)):\n",
        "      red_tuple.append((lines_arr[i][:take],tgt_arr[i][:take],i))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aXXFf-wocWBV"
      },
      "outputs": [],
      "source": [
        "rearr_tuple = []\n",
        "for lines_array, tgt_array, lang_idx in red_tuple:\n",
        "    for i in range(take):\n",
        "        rearr_tuple.append((lines_array[i],tgt_array[i],lang_idx))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7XGDmyKfcy8M"
      },
      "outputs": [],
      "source": [
        "print(len(rearr_tuple))\n",
        "order_rearrange = np.arange(len(rearr_tuple))\n",
        "np.random.shuffle(order_rearrange)\n",
        "rearrange_tuple = [rearr_tuple[i] for i in order_rearrange]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CAQxjEE7ddC9"
      },
      "outputs": [],
      "source": [
        "final_torch, cur_sent, lang_idx = rearrange_tuple[0]\n",
        "sentence_list = [cur_sent]\n",
        "lang_indexes = [lang_idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "apvsW58ue2lS"
      },
      "outputs": [],
      "source": [
        "final_torch = [final_torch]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "izfIBDrpew9E"
      },
      "outputs": [],
      "source": [
        "for i in range(1, len(rearrange_tuple)):\n",
        "    print(i)\n",
        "    cur_torch, cur_sent, cur_idx = rearrange_tuple[i]\n",
        "    sentence_list.append(cur_sent)\n",
        "    lang_indexes.append(cur_idx)\n",
        "    final_torch.append(cur_torch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ANyL_ImtfQsH"
      },
      "outputs": [],
      "source": [
        "final_torch = torch.tensor(final_torch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xMFsJA1u0exF"
      },
      "outputs": [],
      "source": [
        "torch.save(final_torch,'/content/drive/MyDrive/space_torch')\n",
        "np.save('/content/drive/MyDrive/space_sent',np.array(sentence_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3i7iU87qiAKo"
      },
      "outputs": [],
      "source": [
        "lines = torch.load('/content/drive/MyDrive/space_torch')\n",
        "tgt = np.load('/content/drive/MyDrive/space_sent.npy').tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNs6Reimddto"
      },
      "source": [
        "# **Pre Processing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0DSJaJTZfdlV"
      },
      "outputs": [],
      "source": [
        "start_token = '28'\n",
        "end_token = '29'\n",
        "alphabets = 'abcdefghijklmnopqrstuvwxyz'\n",
        "vocab_size = 30\n",
        "alphabet_dict = {}\n",
        "alphabet_dict['start'] = int(start_token) \n",
        "alphabet_dict['end'] = int(end_token)\n",
        "alphabet_dict['_'] = int(space_code)\n",
        "alphabet_dict['pad'] = int(pad_code)\n",
        "alphabet_idx = 0\n",
        "\n",
        "for character in alphabets:\n",
        "    alphabet_dict[character] = alphabet_idx\n",
        "    alphabet_idx += 1\n",
        "\n",
        "\n",
        "def one_hot_encode(sent,start = True, end = True):\n",
        "    num_code = []\n",
        "    input_code = []\n",
        "    if start:\n",
        "        one_code = [0] * vocab_size\n",
        "        one_code[alphabet_dict['start']] = 1\n",
        "        num_code.append(one_code)\n",
        "\n",
        "        input_code.append(alphabet_dict['start'])\n",
        "\n",
        "    for character in sent:\n",
        "        one_code = [0] * vocab_size\n",
        "        one_code[alphabet_dict[character]] = 1\n",
        "        num_code.append(one_code)\n",
        "\n",
        "        input_code.append(alphabet_dict[character])\n",
        "\n",
        "    if end:\n",
        "        one_code = [0] * vocab_size\n",
        "        one_code[alphabet_dict['end']] = 1\n",
        "        num_code.append(one_code)\n",
        "\n",
        "        input_code.append(alphabet_dict['end'])\n",
        "\n",
        "    for i in range(len(num_code), max_len):\n",
        "        one_code = [0] * vocab_size\n",
        "        one_code[alphabet_dict['pad']] = 1\n",
        "        num_code.append(one_code)\n",
        "\n",
        "        input_code.append(alphabet_dict['pad'])\n",
        "\n",
        "    return num_code, input_code\n",
        "\n",
        "def one_hot_code_vocab(lines, start = True, end = True):\n",
        "    one_hot_codes = []\n",
        "    input_codes = []\n",
        "    for line in lines:\n",
        "        num_code, input_code = one_hot_encode(line, start, end)\n",
        "        one_hot_codes.append(num_code) \n",
        "        input_codes.append(input_code)\n",
        "    return torch.FloatTensor(one_hot_codes), torch.tensor(input_codes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ddoPbHCYnJv-"
      },
      "outputs": [],
      "source": [
        "def get_batch(torch_lines, target, batch_idx, batch_size = 32):\n",
        "      start_idx = (batch_idx * batch_size)\n",
        "      end_idx = min((batch_idx + 1)*batch_size, len(target))\n",
        "\n",
        "      one_hot_codes, input_codes = one_hot_code_vocab(target[start_idx : end_idx])\n",
        "      return torch_lines[start_idx : end_idx], input_codes, one_hot_codes, target[start_idx : end_idx]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmAfQs0t_0_b"
      },
      "source": [
        "# **Baseline Model and Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gAkb1LGLA-g9"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "class PositionalEncoding(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        position = torch.arange(max_len).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
        "        pe = torch.zeros(max_len, 1, d_model)\n",
        "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: Tensor, shape [seq_len, batch_size, embedding_dim]\n",
        "        \"\"\"\n",
        "        x = x + self.pe[:x.size(0)]\n",
        "        return self.dropout(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ytC-UJV4--sG"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification, AdamW, DataCollatorWithPadding, \\\n",
        "    get_scheduler\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm.auto import tqdm\n",
        "# from utils import *\n",
        "from solver import *\n",
        "from torch.nn import Transformer, TransformerEncoder, TransformerEncoderLayer, TransformerDecoderLayer, TransformerDecoder\n",
        "import math\n",
        "\n",
        "dropout_prob = 0\n",
        "vocab_size = 30\n",
        "\n",
        "class Deciphormer(torch.nn.Module):\n",
        "    '''\n",
        "    Defining the base model:\n",
        "    1)\n",
        "    '''\n",
        "\n",
        "    def __init__(self, ntoken: int = 30, d_model: int = 512, nhead: int = 8, d_hid: int = 2048, nlayers: int = 6,\n",
        "                 dropout: float = 0.5):\n",
        "        # Initialize model attributes\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.nhead = nhead\n",
        "        self.d_hid = d_hid\n",
        "        self.nlayers = nlayers\n",
        "        self.dropout = dropout\n",
        "\n",
        "        # Define model layers\n",
        "\n",
        "        self.embedder = nn.Embedding(ntoken, d_model)\n",
        "        self.pos_encoder = PositionalEncoding(d_model, max_len = d_model)\n",
        "        encoder_layers = TransformerEncoderLayer(self.d_model, nhead, d_hid, dropout, batch_first = True)\n",
        "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
        "\n",
        "        self.embedder2 = nn.Embedding(vocab_size, d_model)\n",
        "        decoder_layers = TransformerDecoderLayer(d_model, nhead, d_hid, batch_first = True)\n",
        "        self.transformer_decoder = TransformerDecoder(decoder_layers, nlayers)\n",
        "        self.linearout = nn.Linear(d_model, vocab_size)\n",
        "\n",
        "    def forward(self, data, tgt):\n",
        "      src_mask = self.generate_src_mask(data)\n",
        "      src_mask = src_mask.to(device)\n",
        "      src_padding_mask = self.generate_src_padding_mask(data)\n",
        "      src_padding_mask = src_padding_mask.to(device)\n",
        "\n",
        "      src = self.embedder(data) * math.sqrt(self.d_model)\n",
        "      # print(src.shape)\n",
        "      src = self.pos_encoder(src)\n",
        "      # print(src.shape)\n",
        "      out1 = self.transformer_encoder(src, src_mask, src_padding_mask)\n",
        "      # print(out1.shape)\n",
        "\n",
        "      tgt_mask = self.generate_tgt_mask(tgt)\n",
        "      tgt_mask = tgt_mask.to(device)\n",
        "      tgt_padding_mask = self.generate_tgt_padding_mask(tgt)\n",
        "      tgt_padding_mask = tgt_padding_mask.to(device)\n",
        "      embed_tgt = self.embedder2(tgt) * math.sqrt(self.d_model)\n",
        "      out2 = self.transformer_decoder(embed_tgt, out1, tgt_mask, src_mask, tgt_padding_mask, src_padding_mask)\n",
        "      out2 = self.linearout(out2)\n",
        "      return (out1, out2)\n",
        "\n",
        "\n",
        "    def generate_src_mask(self,data):\n",
        "        batch_size = data.shape[0]\n",
        "        seq_len = data.shape[1]\n",
        "\n",
        "        src_mask = torch.zeros(seq_len, seq_len)\n",
        "\n",
        "        return src_mask\n",
        "\n",
        "    def generate_src_padding_mask(self, data):\n",
        "        batch_size = data.shape[0]\n",
        "        seq_len = data.shape[1]\n",
        "\n",
        "        src_padding_mask = torch.full(size = (batch_size,seq_len), fill_value = False)\n",
        "\n",
        "        for i in range(batch_size):\n",
        "            pad_idx = -1\n",
        "            for j in range(seq_len):\n",
        "                if data[i][j] == pad_code:\n",
        "                    pad_idx = j\n",
        "                    break\n",
        "        \n",
        "        if pad_idx != -1:\n",
        "            src_padding_mask[i][pad_idx:] = True\n",
        "\n",
        "        return src_padding_mask\n",
        "\n",
        "    def generate_tgt_mask(self,tgt):\n",
        "        batch_size = tgt.shape[0]\n",
        "        seq_len = tgt.shape[1]\n",
        "        return (torch.triu(torch.ones(seq_len, seq_len)) == 1).transpose(0, 1)\n",
        "\n",
        "    def generate_tgt_padding_mask(self, tgt):\n",
        "        batch_size = tgt.shape[0]\n",
        "        seq_len = tgt.shape[1]\n",
        "\n",
        "        tgt_padding_mask = torch.full(size = (batch_size,seq_len), fill_value = False)\n",
        "\n",
        "        for i in range(batch_size):\n",
        "            pad_idx = -1\n",
        "            for j in range(seq_len):\n",
        "                if tgt[i][j] == pad_code:\n",
        "                    pad_idx = j\n",
        "                    break\n",
        "        \n",
        "        if pad_idx != -1:\n",
        "            tgt_padding_mask[i][pad_idx:] = True\n",
        "\n",
        "        return tgt_padding_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xjO0xBGRBVH5"
      },
      "outputs": [],
      "source": [
        "model = Deciphormer()\n",
        "model.to(device)\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vyrXe002oCUa"
      },
      "outputs": [],
      "source": [
        "model.train()\n",
        "batch_size = 32\n",
        "num_of_batches = lines.shape[0]//batch_size\n",
        "num_of_epochs = 5\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr = 0.01)\n",
        "loss = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in range(num_of_epochs):\n",
        "    for i in range(num_of_batches):\n",
        "        encoder_input, decoder_tgt, decoder_final,_ = get_batch(lines, tgt, i,2)\n",
        "\n",
        "        encoder_input = encoder_input.to(device)\n",
        "        decoder_tgt = decoder_tgt.to(device)\n",
        "        decoder_final = decoder_final.to(device)\n",
        "\n",
        "        model_encoder_out, model_decoder_out = model(encoder_input, decoder_tgt)\n",
        "\n",
        "        loss_tensor = loss(model_decoder_out,decoder_final)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss_tensor.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i + 1)%500==0:\n",
        "            torch.save(model.state_dict(), f'/content/drive/MyDrive/space_model_final_{i+1}_{epoch}')\n",
        "\n",
        "        print(i)\n",
        "    torch.save(model.state_dict(), f'/content/drive/MyDrive/space_{epoch}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggRzd2F48e9m"
      },
      "source": [
        "# **Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "eval_tgt = np.load('/content/drive/MyDrive/test_sent.npy').tolist()"
      ],
      "metadata": {
        "id": "CYzkd36lFmdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Deciphormer()\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/space_model_final_2000_1'))\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "7OXN9NyQHyXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_tensor_spaces(strp_lines):\n",
        "      freq_lines = []\n",
        "      source_lines = []\n",
        "      for line in strp_lines:\n",
        "          freq_lines.append(freq_array(line))\n",
        "      return freq_lines"
      ],
      "metadata": {
        "id": "1GlylZhYF7Xr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_src = torch.tensor(get_tensor_spaces(eval_tgt))"
      ],
      "metadata": {
        "id": "1gQBbVCEGVDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ne_397I5A_TG"
      },
      "outputs": [],
      "source": [
        "rev_alphabet = {}\n",
        "for key in alphabet_dict.keys():\n",
        "    rev_alphabet[alphabet_dict[key]] = key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PNdatG0_8zZi"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "num_of_batches = eval_src.shape[0]\n",
        "\n",
        "predicted_sentences = []\n",
        "true_sentences = []\n",
        "\n",
        "for i in range(num_of_batches):\n",
        "    encoder_input, decoder_tgt, decoder_final, target_sentences = get_batch(eval_src, eval_tgt, i, batch_size = 1)\n",
        "    encoder_input = encoder_input.to(device)\n",
        "    pred_sentence = ''\n",
        "    for j in range(len(target_sentences[0])):\n",
        "        decoder_one_hot, decoder_tgt = one_hot_code_vocab([pred_sentence], start = True, end = False)\n",
        "        decoder_tgt = decoder_tgt.to(device)\n",
        "\n",
        "        model_encoder_out, model_decoder_out = model(encoder_input, decoder_tgt)\n",
        "        logits = model_decoder_out.detach().cpu().numpy()\n",
        "        \n",
        "        logits = logits.squeeze()\n",
        "\n",
        "        pred_char = np.argmax(logits[j])\n",
        "        if(pred_char == end_token):\n",
        "              break\n",
        "        elif(pred_char == space_code):\n",
        "              pred_sentence = ' '\n",
        "        elif(pred_char < 26):\n",
        "              pred_sentence += rev_alphabet[pred_char]\n",
        "\n",
        "    predicted_sentences.append(pred_sentence)\n",
        "    true_sentences.append(target_sentences[0])\n",
        "    if ((i+1)%100)==0:\n",
        "        np.save('/content/drive/MyDrive/predsent',np.array(predicted_sentences))\n",
        "        np.save('/content/drive/MyDrive/truesent',np.array(true_sentences))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goNhbYHs6WTV"
      },
      "source": [
        "# **Evaluation Metrics**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O3h-6Vl56Ze9"
      },
      "outputs": [],
      "source": [
        "np_pred = np.array(predicted_sentences)\n",
        "np_true = np.array(true_sentences)\n",
        "np.save('pred_arr', np_pred)\n",
        "np.save('true_arr', np_true)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kShY7FeiNTz-"
      },
      "outputs": [],
      "source": [
        "!pip install pyter3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vM78BEY1NU8W"
      },
      "outputs": [],
      "source": [
        "import pyter\n",
        "ter_lis = []\n",
        "for i in range(len(predicted_sentences)):\n",
        "    ter_lis.append(pyter.ter(predicted_sentences[i],true_sentences[i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "19m2lXJfNuPl"
      },
      "outputs": [],
      "source": [
        "print(sum(ter_lis)/len(ter_lis))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "685_Project_space.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}